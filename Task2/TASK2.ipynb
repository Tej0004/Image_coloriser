{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Interactive Colorization GUI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tej Bachhav\\AppData\\Local\\Temp\\ipykernel_28652\\744904542.py:333: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch._dynamo\n",
    "# Suppress errors from torch.compile to fall back to eager mode if needed\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk, messagebox\n",
    "import threading\n",
    "from pycocotools.coco import COCO\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import sys\n",
    "\n",
    "def remove_orig_mod_prefix(state_dict):\n",
    "    \"\"\"\n",
    "    Remove the '_orig_mod.' prefix from keys in a state dict.\n",
    "    If both a prefixed and unprefixed key exist for the same parameter,\n",
    "    the cleaned (unprefixed) version from the prefixed key is used.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    # First, add all keys that have the prefix (cleaned)\n",
    "    for key, value in state_dict.items():\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            cleaned[key[len(\"_orig_mod.\"):]] = value\n",
    "    # Then, add keys that do not have the prefix only if they don't conflict.\n",
    "    for key, value in state_dict.items():\n",
    "        if not key.startswith(\"_orig_mod.\"):\n",
    "            if key not in cleaned:\n",
    "                cleaned[key] = value\n",
    "    return cleaned\n",
    "\n",
    "def download_dataset():\n",
    "    \"\"\"Downloads the COCO dataset for semantic segmentation and colorization.\"\"\"\n",
    "    if not os.path.exists(\"datasets\"):\n",
    "        os.makedirs(\"datasets\")\n",
    "    if not os.path.exists(\"datasets/val2017\"):\n",
    "        print(\"Downloading COCO dataset...\")\n",
    "        url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "        urllib.request.urlretrieve(url, \"val2017.zip\")\n",
    "        with zipfile.ZipFile(\"val2017.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"datasets\")\n",
    "        os.remove(\"val2017.zip\")\n",
    "        print(\"Dataset downloaded and extracted successfully!\")\n",
    "    else:\n",
    "        print(\"Dataset already exists!\")\n",
    "\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, size=(256, 256)):\n",
    "        self.image_dir = image_dir\n",
    "        # Reduce dataset size for faster training\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')][:500]\n",
    "        self.transform = transform\n",
    "        self.size = size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.resize(self.size, Image.Resampling.LANCZOS)\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        # Convert to LAB color space\n",
    "        lab_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
    "        \n",
    "        # Normalize L channel to [-1, 1]\n",
    "        l_channel = lab_image[:, :, 0].astype(np.float32) / 50.0 - 1.0\n",
    "        \n",
    "        # Normalize ab channels to [-1, 1]\n",
    "        ab_channels = lab_image[:, :, 1:].astype(np.float32)\n",
    "        ab_channels = (ab_channels - 128.0) / 128.0\n",
    "        \n",
    "        # Create a binary mask using edge detection and thresholding\n",
    "        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "        mask = dilated > 0\n",
    "        \n",
    "        if self.transform:\n",
    "            # For L: convert normalized values back to [0,255] for PIL conversion, then re-normalize\n",
    "            l_img = Image.fromarray(((l_channel + 1.0) * 50.0).astype(np.uint8))\n",
    "            l_tensor = self.transform(l_img)\n",
    "            l_tensor = l_tensor * 2.0 - 1.0\n",
    "            \n",
    "            # For ab channels: convert with shape (H,W,2) to tensor\n",
    "            ab_tensor = torch.from_numpy(ab_channels.transpose((2, 0, 1))).float()\n",
    "            mask_tensor = torch.from_numpy(mask.astype(np.float32))\n",
    "            \n",
    "            return l_tensor, ab_tensor, mask_tensor\n",
    "        else:\n",
    "            return (torch.from_numpy(l_channel).unsqueeze(0),\n",
    "                    torch.from_numpy(ab_channels.transpose((2, 0, 1))),\n",
    "                    torch.from_numpy(mask.astype(np.float32)))\n",
    "\n",
    "class SegColorizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegColorizer, self).__init__()\n",
    "        \n",
    "        # Improved encoder with residual connections\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Segmentation branch\n",
    "        self.seg_branch = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=1),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "        \n",
    "        # Colorization branch with improved upsampling\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(257, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 2, kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Encoding\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        \n",
    "        # Segmentation\n",
    "        seg_output = self.seg_branch(enc3)\n",
    "        \n",
    "        if mask is not None:\n",
    "            seg_mask = mask.unsqueeze(1)\n",
    "        else:\n",
    "            seg_mask = torch.sigmoid(seg_output)\n",
    "        \n",
    "        # Combine features with segmentation mask\n",
    "        seg_small = nn.functional.interpolate(seg_mask, size=enc3.shape[2:], mode='bilinear', align_corners=True)\n",
    "        combined = torch.cat([enc3, seg_small], dim=1)\n",
    "        \n",
    "        # Decoding with skip connections\n",
    "        dec3 = self.dec3(combined)\n",
    "        dec2 = self.dec2(dec3)\n",
    "        color_output = self.dec1(dec2)\n",
    "        \n",
    "        return color_output, seg_output\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cpu':\n",
    "        print(\"WARNING: GPU not detected. Training will be slow!\")\n",
    "    else:\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "        \n",
    "    model = model.to(device)\n",
    "    # For Windows systems, disable multiprocessing in DataLoader\n",
    "    num_workers = 0 if sys.platform.startswith('win') else 2\n",
    "\n",
    "    # Use torch.compile for potential speedup; falls back to eager mode if needed.\n",
    "    model = torch.compile(model)\n",
    "    \n",
    "    criterion_color = nn.MSELoss().to(device)\n",
    "    criterion_seg = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0]).to(device)).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "    \n",
    "    scaler = torch.amp.GradScaler(device='cuda')\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    metrics = {'train_loss': [], 'val_loss': [], 'precision': [], 'recall': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (l_channel, ab_channels, mask) in enumerate(pbar):\n",
    "            l_channel = l_channel.to(device, non_blocking=True)\n",
    "            ab_channels = ab_channels.to(device, non_blocking=True)\n",
    "            mask = mask.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                color_output, seg_output = model(l_channel, mask)\n",
    "                loss_color = criterion_color(color_output, ab_channels)\n",
    "                loss_seg = criterion_seg(seg_output, mask.unsqueeze(1).float())\n",
    "                loss = 0.7 * loss_color + 0.3 * loss_seg\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 5 == 0:\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{scheduler.get_last_lr()[0]:.6f}'})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_masks = []\n",
    "        \n",
    "        with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "            for l_channel, ab_channels, mask in val_loader:\n",
    "                l_channel = l_channel.to(device, non_blocking=True)\n",
    "                ab_channels = ab_channels.to(device, non_blocking=True)\n",
    "                mask = mask.to(device, non_blocking=True)\n",
    "                \n",
    "                color_output, seg_output = model(l_channel)\n",
    "                loss_color = criterion_color(color_output, ab_channels)\n",
    "                loss_seg = criterion_seg(seg_output, mask.unsqueeze(1).float())\n",
    "                val_loss += (0.7 * loss_color + 0.3 * loss_seg).item()\n",
    "                \n",
    "                pred_masks = (torch.sigmoid(seg_output) > 0.5).float()\n",
    "                all_preds.extend(pred_masks.cpu().numpy().flatten())\n",
    "                all_masks.extend((mask.cpu().numpy() > 0.5).flatten())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        precision = precision_score(all_masks, all_preds, zero_division=1)\n",
    "        recall = recall_score(all_masks, all_preds, zero_division=1)\n",
    "        \n",
    "        metrics['train_loss'].append(train_loss / len(train_loader))\n",
    "        metrics['val_loss'].append(val_loss)\n",
    "        metrics['precision'].append(precision)\n",
    "        metrics['recall'].append(recall)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}\\n')\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, 'best_model.pth')\n",
    "            print(f'Saved new best model with loss: {best_loss:.4f}')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def enhance_saturation(image, factor=1.5):\n",
    "    \"\"\"\n",
    "    Enhance the saturation of a given RGB image by the specified factor.\n",
    "    \"\"\"\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # Increase the saturation channel\n",
    "    hsv[:, :, 1] = np.clip(hsv[:, :, 1].astype(np.float32) * factor, 0, 255).astype(np.uint8)\n",
    "    # Convert back to RGB\n",
    "    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return enhanced\n",
    "\n",
    "class InteractiveColorizationGUI:\n",
    "    def __init__(self, model_path='best_model.pth'):\n",
    "        self.window = tk.Tk()\n",
    "        self.window.title(\"Interactive Image Colorization\")\n",
    "        self.window.geometry(\"1200x800\")\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = SegColorizer().to(self.device)\n",
    "        if os.path.exists(model_path):\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "            state_dict = remove_orig_mod_prefix(checkpoint['model_state_dict'])\n",
    "            self.model.load_state_dict(state_dict)\n",
    "            self.model.eval()\n",
    "            \n",
    "        self.setup_gui()\n",
    "        \n",
    "    def setup_gui(self):\n",
    "        control_panel = ttk.Frame(self.window, padding=\"10\")\n",
    "        control_panel.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        \n",
    "        ttk.Button(control_panel, text=\"Load Image\", command=self.load_image).grid(row=0, column=0, pady=5)\n",
    "        ttk.Label(control_panel, text=\"Select Regions to Colorize:\").grid(row=1, column=0, pady=5)\n",
    "        \n",
    "        self.region_vars = {\n",
    "            'Foreground': tk.BooleanVar(value=True),\n",
    "            'Background': tk.BooleanVar(value=True)\n",
    "        }\n",
    "        \n",
    "        row = 2\n",
    "        for region, var in self.region_vars.items():\n",
    "            ttk.Checkbutton(control_panel, text=region, variable=var, command=self.update_preview).grid(row=row, column=0)\n",
    "            row += 1\n",
    "            \n",
    "        ttk.Button(control_panel, text=\"Colorize\", command=self.colorize_image).grid(row=row, column=0, pady=10)\n",
    "        \n",
    "        self.canvas = tk.Canvas(self.window, width=800, height=600)\n",
    "        self.canvas.grid(row=0, column=1, padx=10, pady=10)\n",
    "        \n",
    "        self.progress = ttk.Progressbar(self.window, orient=\"horizontal\", length=200, mode=\"determinate\")\n",
    "        self.progress.grid(row=1, column=1, padx=10, pady=5)\n",
    "        \n",
    "        self.window.grid_columnconfigure(1, weight=1)\n",
    "        self.window.grid_rowconfigure(0, weight=1)\n",
    "        \n",
    "        self.original_image = None\n",
    "        self.processed_image = None\n",
    "        self.mask = None\n",
    "        \n",
    "    def load_image(self):\n",
    "        try:\n",
    "            file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp\")])\n",
    "            if file_path:\n",
    "                image = Image.open(file_path).convert('RGB')\n",
    "                image = image.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "                self.original_image = image\n",
    "                self.display_image(image)\n",
    "                self.generate_segmentation()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading image: {str(e)}\")\n",
    "            \n",
    "    def generate_segmentation(self):\n",
    "        if self.original_image is None:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            image_np = np.array(self.original_image)\n",
    "            lab_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
    "            # Mimic conversion for L channel\n",
    "            l_channel = lab_image[:, :, 0].astype(np.float32) / 50.0 - 1.0\n",
    "            l_tensor = torch.from_numpy(l_channel).unsqueeze(0).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "                _, seg_output = self.model(l_tensor)\n",
    "                self.mask = torch.sigmoid(seg_output).cpu().numpy()[0, 0]\n",
    "            self.update_preview()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error generating segmentation: {str(e)}\")\n",
    "            \n",
    "    def update_preview(self):\n",
    "        if self.mask is None:\n",
    "            return\n",
    "        try:\n",
    "            # Use continuous threshold for preview\n",
    "            preview_mask = (self.mask > 0.5)\n",
    "            preview = np.array(self.original_image)\n",
    "            gray = cv2.cvtColor(preview, cv2.COLOR_RGB2GRAY)\n",
    "            gray_rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "            preview[~preview_mask] = gray_rgb[~preview_mask]\n",
    "            self.display_image(Image.fromarray(preview))\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error updating preview: {str(e)}\")\n",
    "            \n",
    "    def colorize_image(self):\n",
    "        if self.original_image is None:\n",
    "            return\n",
    "        try:\n",
    "            image_np = np.array(self.original_image)\n",
    "            lab_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
    "            l_channel = lab_image[:, :, 0].astype(np.float32) / 50.0 - 1.0\n",
    "            l_tensor = torch.from_numpy(l_channel).unsqueeze(0).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            # Get continuous mask probabilities for blending\n",
    "            with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "                _, seg_output = self.model(l_tensor)\n",
    "                mask_prob = torch.sigmoid(seg_output).cpu().numpy()[0, 0]\n",
    "            \n",
    "            # Determine blending weight based on user options\n",
    "            if self.region_vars['Foreground'].get() and not self.region_vars['Background'].get():\n",
    "                blend = mask_prob\n",
    "            elif self.region_vars['Background'].get() and not self.region_vars['Foreground'].get():\n",
    "                blend = 1 - mask_prob\n",
    "            elif self.region_vars['Foreground'].get() and self.region_vars['Background'].get():\n",
    "                blend = np.ones_like(mask_prob)\n",
    "            else:\n",
    "                blend = np.zeros_like(mask_prob)\n",
    "            \n",
    "            # Use binary mask (threshold 0.5) for ab channel generation\n",
    "            binary_mask = (mask_prob > 0.5).astype(np.float32)\n",
    "            mask_tensor = torch.from_numpy(binary_mask).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "                color_output, _ = self.model(l_tensor, mask_tensor)\n",
    "                ab_channels = color_output.cpu().numpy()[0]\n",
    "                ab_channels = ab_channels.transpose(1, 2, 0)\n",
    "                ab_channels = ab_channels * 128.0 + 128.0\n",
    "            colorized_lab = np.concatenate([lab_image[:, :, 0:1], ab_channels], axis=2)\n",
    "            colorized_rgb = cv2.cvtColor(colorized_lab.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "            gray_img = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "            gray_rgb = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n",
    "            blend = blend[..., np.newaxis]\n",
    "            final_result = blend * colorized_rgb + (1 - blend) * gray_rgb\n",
    "\n",
    "            # --- Enhancement Step: Increase Saturation ---\n",
    "            final_result = final_result.astype(np.uint8)\n",
    "            final_result = enhance_saturation(final_result, factor=1.5)\n",
    "            # -------------------------------------------------\n",
    "\n",
    "            self.display_image(Image.fromarray(final_result))\n",
    "            \n",
    "            if messagebox.askyesno(\"Save\", \"Would you like to save the colorized image?\"):\n",
    "                save_path = filedialog.asksaveasfilename(defaultextension=\".png\",\n",
    "                                                        filetypes=[(\"PNG files\", \"*.png\"),\n",
    "                                                                  (\"JPEG files\", \"*.jpg\"),\n",
    "                                                                  (\"All files\", \"*.*\")])\n",
    "                if save_path:\n",
    "                    Image.fromarray(final_result).save(save_path)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error during colorization: {str(e)}\")\n",
    "            \n",
    "    def display_image(self, image):\n",
    "        display_size = (800, 600)\n",
    "        image.thumbnail(display_size, Image.Resampling.LANCZOS)\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.canvas.create_image(400, 300, image=photo)\n",
    "        self.canvas.image = photo  # Keep reference\n",
    "        \n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "\n",
    "class ColorizationSystem:\n",
    "    def __init__(self, model_path='best_model.pth', image_size=(256, 256)):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = SegColorizer().to(self.device)\n",
    "        self.image_size = image_size\n",
    "        if os.path.exists(model_path):\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "            state_dict = remove_orig_mod_prefix(checkpoint['model_state_dict'])\n",
    "            self.model.load_state_dict(state_dict)\n",
    "            self.model.eval()\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Model file {model_path} not found!\")\n",
    "    \n",
    "    def process_image(self, image_path, output_path, colorize_foreground=True, colorize_background=True):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize(self.image_size, Image.Resampling.LANCZOS)\n",
    "        image_np = np.array(image)\n",
    "        lab_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
    "        l_channel = lab_image[:, :, 0].astype(np.float32) / 50.0 - 1.0\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(self.image_size, antialias=True)\n",
    "        ])\n",
    "        l_tensor = transform(Image.fromarray(((l_channel + 1.0) * 50.0).astype(np.uint8))).unsqueeze(0)\n",
    "        with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "            l_tensor = l_tensor.to(self.device)\n",
    "            _, seg_output = self.model(l_tensor)\n",
    "            mask_prob = torch.sigmoid(seg_output).cpu().numpy()[0, 0]\n",
    "        if colorize_foreground and not colorize_background:\n",
    "            blend = mask_prob\n",
    "        elif colorize_background and not colorize_foreground:\n",
    "            blend = 1 - mask_prob\n",
    "        elif colorize_foreground and colorize_background:\n",
    "            blend = np.ones_like(mask_prob)\n",
    "        else:\n",
    "            blend = np.zeros_like(mask_prob)\n",
    "        binary_mask = (mask_prob > 0.5).astype(np.float32)\n",
    "        mask_tensor = torch.from_numpy(binary_mask).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "            mask_tensor = mask_tensor.to(self.device)\n",
    "            color_output, _ = self.model(l_tensor, mask_tensor)\n",
    "            ab_channels = color_output.cpu().numpy()[0]\n",
    "            ab_channels = ab_channels.transpose(1, 2, 0)\n",
    "            ab_channels = ab_channels * 128.0 + 128.0\n",
    "        colorized_lab = np.concatenate([lab_image[:, :, 0:1], ab_channels], axis=2)\n",
    "        colorized_rgb = cv2.cvtColor(colorized_lab.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "        gray_img = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "        gray_rgb = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n",
    "        blend = blend[..., np.newaxis]\n",
    "        final_result = blend * colorized_rgb + (1 - blend) * gray_rgb\n",
    "\n",
    "        # --- Enhancement Step: Increase Saturation ---\n",
    "        final_result = final_result.astype(np.uint8)\n",
    "        final_result = enhance_saturation(final_result, factor=1.5)\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        Image.fromarray(final_result).save(output_path)\n",
    "        return output_path\n",
    "\n",
    "def cli_interface():\n",
    "    \"\"\"Command-line Image Colorization Interface\"\"\"\n",
    "    print(\"Command-line Image Colorization Interface\")\n",
    "    while True:\n",
    "        image_path = input(\"Enter path to input image: \").strip().replace('\\\"', '')\n",
    "        if os.path.exists(image_path):\n",
    "            break\n",
    "        print(\"File not found. Please try again.\")\n",
    "    output_path = input(\"Enter path for output image (press Enter for auto-generated): \").strip()\n",
    "    if not output_path:\n",
    "        output_dir = \"output\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_colorized.png\")\n",
    "    colorize_foreground = input(\"Colorize foreground? (y/n): \").lower().startswith('y')\n",
    "    colorize_background = input(\"Colorize background? (y/n): \").lower().startswith('y')\n",
    "    try:\n",
    "        system = ColorizationSystem(image_size=(256, 256))\n",
    "        result_path = system.process_image(image_path, output_path, colorize_foreground, colorize_background)\n",
    "        print(f\"Colorized image saved to: {result_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def check_display():\n",
    "    \"\"\"Check if a display server is available (for GUI).\"\"\"\n",
    "    try:\n",
    "        tk.Tk().destroy()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists('best_model.pth'):\n",
    "        print(\"No pre-trained model found. Starting training...\")\n",
    "        download_dataset()\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        train_dataset = ColorizationDataset(\"datasets/val2017\", transform=transform)\n",
    "        val_dataset = ColorizationDataset(\"datasets/val2017\", transform=transform)\n",
    "        \n",
    "        # For Windows, set num_workers to 0 to avoid multiprocessing issues.\n",
    "        num_workers = 0 if sys.platform.startswith('win') else 2\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=16, \n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=32, \n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        model = SegColorizer()\n",
    "        metrics = train_model(model, train_loader, val_loader)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(metrics['train_loss'], label='Train Loss')\n",
    "        plt.plot(metrics['val_loss'], label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Loss over time')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(metrics['precision'], label='Precision')\n",
    "        plt.plot(metrics['recall'], label='Recall')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.title('Metrics over time')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_metrics.png')\n",
    "        plt.close()\n",
    "        print(\"Training completed. Model saved as 'best_model.pth'\")\n",
    "    if check_display():\n",
    "        print(\"Starting Interactive Colorization GUI...\")\n",
    "        app = InteractiveColorizationGUI()\n",
    "        app.run()\n",
    "    else:\n",
    "        print(\"No display detected. Starting command-line interface...\")\n",
    "        cli_interface()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tej",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
